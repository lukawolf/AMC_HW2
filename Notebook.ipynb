{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0621f1-1cf5-4415-b180-6ff0e66e0739",
   "metadata": {},
   "source": [
    "# Machine Learning Programming Exercise\n",
    "An Analytical Methods in Cancer Genomics project by Lukáš Cakl `cakll@natur.cuni.cz`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d75ffe7-0620-442e-9df6-906d7c1cc007",
   "metadata": {},
   "source": [
    "## Step 1 - fetching the data\n",
    "Here our dataset will be explained, fetched, read and split into its main components.\n",
    "\n",
    "The dataset available was provided as part of the exercise [here](https://gear.embl.de/data/.slides/deletion.tsv.gz). It contains the following features:\n",
    "- size: Size of the deletion\n",
    "- vac: How many alleles have the deletion (2504 diploid samples -> 5008 alleles in total)\n",
    "- vaf: Allele frequency (simply vac/5008)\n",
    "- pass: 1 - Deletion prediction passed all algorithm filters, 0 – deletion did not pass all filters\n",
    "- missingrate: Fraction of samples not genotyped for this deletion\n",
    "- precise: 1 - The deletion has single-nucleotide resolution, 0 - only approximate breakpoints are known\n",
    "- ci: Confidence interval size around the deletion breakpoints (how sure is the algorithm about the breakpoint)\n",
    "- ce: DNA sequence entropy of the deletion\n",
    "- refgq: Average genotype quality of homozygous reference samples\n",
    "- altgq: Average genotype quality of deletion carrier samples\n",
    "- rdratio: Read-depth ratio of deletion carriers compared to deletion non-carriers\n",
    "- altratio: Average fraction of reads supporting the deletion in a carrier sample\n",
    "- refratio: Average fraction of reads supporting the deletion in a non-carrier sample\n",
    "- maxaltratio: Maximum fraction of reads supporting the deletion in a carrier sample\n",
    "- status: 1 – likely true deletion, 0 – likely false deletion, NA – unlabeled (deletion could be true or false)\n",
    "\n",
    "To download the data we use urllib. We also check if it already exists localy to save on bandwidth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "608e1c27-3308-4cd1-9ef5-0e110ce06c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No download neccessary\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import os\n",
    "\n",
    "datasetUrl = 'https://gear.embl.de/data/.slides/deletion.tsv.gz'\n",
    "def downloadData(sourceUrl, localFile, localPath):\n",
    "    if not os.path.isdir(localPath):\n",
    "        os.makedirs(localPath)\n",
    "    localUri = os.path.join(localPath, localFile)\n",
    "    if not os.path.exists(localUri):\n",
    "        urllib.request.urlretrieve(sourceUrl, localUri)\n",
    "        print('Dataset downloaded')\n",
    "    else:\n",
    "        print('No download neccessary')\n",
    "downloadData(datasetUrl, 'deletion.tsv.gz', './data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d0b72-c1e3-463a-a2df-033eb7a538b1",
   "metadata": {},
   "source": [
    "Then we parse the dataset into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1bb6f94-2fc0-416c-9819-caf5efcadcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr_start_end</th>\n",
       "      <th>id</th>\n",
       "      <th>size</th>\n",
       "      <th>vac</th>\n",
       "      <th>vaf</th>\n",
       "      <th>pass</th>\n",
       "      <th>missingrate</th>\n",
       "      <th>precise</th>\n",
       "      <th>ci</th>\n",
       "      <th>ce</th>\n",
       "      <th>refgq</th>\n",
       "      <th>altgq</th>\n",
       "      <th>rdratio</th>\n",
       "      <th>refratio</th>\n",
       "      <th>altratio</th>\n",
       "      <th>maxaltratio</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1_597938_598745</td>\n",
       "      <td>DEL00000012</td>\n",
       "      <td>808</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0</td>\n",
       "      <td>287</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>0.945455</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1_713026_713083</td>\n",
       "      <td>DEL00000018</td>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001399</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.90770</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>0.648186</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1_778727_778781</td>\n",
       "      <td>DEL00000020</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.92127</td>\n",
       "      <td>96</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.668154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1_938037_938670</td>\n",
       "      <td>DEL00000080</td>\n",
       "      <td>634</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.92573</td>\n",
       "      <td>102</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.434565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1_1053192_1053244</td>\n",
       "      <td>DEL00000114</td>\n",
       "      <td>53</td>\n",
       "      <td>307</td>\n",
       "      <td>0.061302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>1.87118</td>\n",
       "      <td>78</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.717275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27100</th>\n",
       "      <td>chrX_155250109_155250983</td>\n",
       "      <td>DEL00202501</td>\n",
       "      <td>875</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>136</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>54</td>\n",
       "      <td>21</td>\n",
       "      <td>0.964944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27101</th>\n",
       "      <td>chrX_155265807_155266142</td>\n",
       "      <td>DEL00202508</td>\n",
       "      <td>336</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.88236</td>\n",
       "      <td>48</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.522206</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27102</th>\n",
       "      <td>chrX_155666910_155667807</td>\n",
       "      <td>DEL00202560</td>\n",
       "      <td>898</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.90604</td>\n",
       "      <td>54</td>\n",
       "      <td>135</td>\n",
       "      <td>0.499575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27103</th>\n",
       "      <td>chrX_155819916_155819986</td>\n",
       "      <td>DEL00202579</td>\n",
       "      <td>71</td>\n",
       "      <td>18</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.98825</td>\n",
       "      <td>81</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.627721</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27104</th>\n",
       "      <td>chrX_155877281_155877882</td>\n",
       "      <td>DEL00202582</td>\n",
       "      <td>602</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.92273</td>\n",
       "      <td>81</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.625286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27105 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  chr_start_end           id  size  vac       vaf  pass  \\\n",
       "0            chr1_597938_598745  DEL00000012   808    1  0.000200     0   \n",
       "1            chr1_713026_713083  DEL00000018    58    7  0.001399     1   \n",
       "2            chr1_778727_778781  DEL00000020    55    1  0.000200     1   \n",
       "3            chr1_938037_938670  DEL00000080   634   10  0.001997     1   \n",
       "4          chr1_1053192_1053244  DEL00000114    53  307  0.061302     1   \n",
       "...                         ...          ...   ...  ...       ...   ...   \n",
       "27100  chrX_155250109_155250983  DEL00202501   875   10  0.001997     1   \n",
       "27101  chrX_155265807_155266142  DEL00202508   336    2  0.000399     1   \n",
       "27102  chrX_155666910_155667807  DEL00202560   898    1  0.000200     1   \n",
       "27103  chrX_155819916_155819986  DEL00202579    71   18  0.003594     1   \n",
       "27104  chrX_155877281_155877882  DEL00202582   602    1  0.000200     1   \n",
       "\n",
       "       missingrate  precise   ci       ce  refgq  altgq   rdratio  refratio  \\\n",
       "0         0.001997        0  287  0.00000     26     11  0.945455       0.0   \n",
       "1         0.000799        1    6  1.90770     21     28  0.648186       0.0   \n",
       "2         0.000000        1    2  1.92127     96  10000  0.668154       0.0   \n",
       "3         0.000000        1    5  1.92573    102  10000  0.434565       0.0   \n",
       "4         0.000000        1   24  1.87118     78  10000  0.717275       0.0   \n",
       "...            ...      ...  ...      ...    ...    ...       ...       ...   \n",
       "27100     0.000000        0  136  0.00000     54     21  0.964944       0.0   \n",
       "27101     0.000000        1    5  1.88236     48  10000  0.522206       0.0   \n",
       "27102     0.000000        1    5  1.90604     54    135  0.499575       0.0   \n",
       "27103     0.000000        1    8  1.98825     81  10000  0.627721       0.0   \n",
       "27104     0.000000        1    5  1.92273     81  10000  0.625286       0.0   \n",
       "\n",
       "       altratio  maxaltratio  status  \n",
       "0      0.285714     0.285714     NaN  \n",
       "1      0.500000     0.888889     NaN  \n",
       "2      0.547619     0.547619     NaN  \n",
       "3      0.545455     1.000000     NaN  \n",
       "4      0.590909     1.000000     NaN  \n",
       "...         ...          ...     ...  \n",
       "27100  0.090909     1.000000     NaN  \n",
       "27101  0.636364     0.636364     NaN  \n",
       "27102  0.291667     0.291667     NaN  \n",
       "27103  0.536585     0.884615     NaN  \n",
       "27104  0.333333     0.333333     NaN  \n",
       "\n",
       "[27105 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"./data/deletion.tsv.gz\", delimiter='\\t', compression='gzip')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd1620a-88e3-48a2-a598-85cf9ce68eea",
   "metadata": {},
   "source": [
    "We trim out the chr_start_end and id columns, which will not be used in the machine learning parts. We save the id for later so we can output our predictions on a per-id basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "634e0513-f7b3-41aa-b10b-787ad9961a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = dataset[\"id\"]\n",
    "dataset = dataset.drop([\"chr_start_end\", \"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154e4f9-7013-43db-a000-b37975fc3291",
   "metadata": {},
   "source": [
    "And we split the unknown data (status NaN) from the data we will use for training and testing the model.\n",
    "We also drop the target column and save it separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51869b92-2267-4e53-a507-316bc33378dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "unknownDataset = dataset[np.isnan(dataset[\"status\"])]\n",
    "unknownDataset = unknownDataset.drop([\"status\"], axis=1)\n",
    "unknownIds = ids[np.isnan(dataset[\"status\"])]\n",
    "knownDataset = dataset[np.invert(np.isnan(dataset[\"status\"]))]\n",
    "knownTarget = knownDataset[\"status\"]\n",
    "knownDataset = knownDataset.drop([\"status\"], axis=1)\n",
    "knownIds = ids[np.invert(np.isnan(dataset[\"status\"]))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f19b025-4afb-4cf6-a00c-e323de0a9e92",
   "metadata": {},
   "source": [
    "## Step 2 - dataset exploration\n",
    "In this step we explore the available dataset using describe and PCA. This is just to get a handle on the data and see if some feature engineering is required (e.q. scaling certain values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb3f4a6-c850-46c1-bba9-cc7001d8bb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "      <th>vac</th>\n",
       "      <th>vaf</th>\n",
       "      <th>pass</th>\n",
       "      <th>missingrate</th>\n",
       "      <th>precise</th>\n",
       "      <th>ci</th>\n",
       "      <th>ce</th>\n",
       "      <th>refgq</th>\n",
       "      <th>altgq</th>\n",
       "      <th>rdratio</th>\n",
       "      <th>refratio</th>\n",
       "      <th>altratio</th>\n",
       "      <th>maxaltratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "      <td>1439.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>284.558721</td>\n",
       "      <td>183.475330</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>0.965949</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>0.876998</td>\n",
       "      <td>21.333565</td>\n",
       "      <td>1.660749</td>\n",
       "      <td>89.348158</td>\n",
       "      <td>7976.104934</td>\n",
       "      <td>0.633950</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.477501</td>\n",
       "      <td>0.609359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>270.905760</td>\n",
       "      <td>578.185304</td>\n",
       "      <td>0.116512</td>\n",
       "      <td>0.181424</td>\n",
       "      <td>0.034514</td>\n",
       "      <td>0.328554</td>\n",
       "      <td>55.636236</td>\n",
       "      <td>0.632800</td>\n",
       "      <td>370.364053</td>\n",
       "      <td>4004.093931</td>\n",
       "      <td>0.172112</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.159454</td>\n",
       "      <td>0.224770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.822565</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.528501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.478261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>148.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.915120</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.600852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>442.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.958650</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>0.686155</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.690065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>998.000000</td>\n",
       "      <td>4517.000000</td>\n",
       "      <td>0.901957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.821885</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>514.000000</td>\n",
       "      <td>1.999220</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>1.842420</td>\n",
       "      <td>0.157895</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              size          vac          vaf         pass  missingrate  \\\n",
       "count  1439.000000  1439.000000  1439.000000  1439.000000  1439.000000   \n",
       "mean    284.558721   183.475330     0.037053     0.965949     0.002652   \n",
       "std     270.905760   578.185304     0.116512     0.181424     0.034514   \n",
       "min      52.000000     1.000000     0.000200     0.000000     0.000000   \n",
       "25%      75.000000     1.000000     0.000200     1.000000     0.000000   \n",
       "50%     148.000000     3.000000     0.000599     1.000000     0.000000   \n",
       "75%     442.000000    26.000000     0.005391     1.000000     0.000000   \n",
       "max     998.000000  4517.000000     0.901957     1.000000     0.821885   \n",
       "\n",
       "           precise           ci           ce         refgq         altgq  \\\n",
       "count  1439.000000  1439.000000  1439.000000   1439.000000   1439.000000   \n",
       "mean      0.876998    21.333565     1.660749     89.348158   7976.104934   \n",
       "std       0.328554    55.636236     0.632800    370.364053   4004.093931   \n",
       "min       0.000000     1.000000     0.000000      5.000000      3.000000   \n",
       "25%       1.000000     3.000000     1.822565     72.000000  10000.000000   \n",
       "50%       1.000000     4.000000     1.915120     78.000000  10000.000000   \n",
       "75%       1.000000     8.000000     1.958650     84.000000  10000.000000   \n",
       "max       1.000000   514.000000     1.999220  10000.000000  10000.000000   \n",
       "\n",
       "           rdratio     refratio     altratio  maxaltratio  \n",
       "count  1439.000000  1439.000000  1439.000000  1439.000000  \n",
       "mean      0.633950     0.001194     0.477501     0.609359  \n",
       "std       0.172112     0.009814     0.159454     0.224770  \n",
       "min       0.003728     0.000000     0.055556     0.066667  \n",
       "25%       0.528501     0.000000     0.437500     0.478261  \n",
       "50%       0.600852     0.000000     0.500000     0.571429  \n",
       "75%       0.686155     0.000000     0.562500     0.690065  \n",
       "max       1.842420     0.157895     1.000000     1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knownDataset.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4913849b-a67c-49c1-b139-7b817e66267c",
   "metadata": {},
   "source": [
    "Just from the dataset description we can see many features (size, vac, refgq...) which are on a vastly larger scale than e.g. vaf. Such features will probably require scaling to not overshadow others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582e4041-6efa-45b5-9dd9-e8c6887a2e33",
   "metadata": {},
   "source": [
    "### PCA\n",
    "PCA is an useful method of dimensionality reduction, which I will be using to explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee675f9-5ab4-427b-9818-f6bce7cb89e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.45354620e-03  3.96215082e-02  8.11860835e-06 -1.46790350e-05\n",
      "   1.20131552e-06 -2.37440708e-05  4.97058527e-03 -5.42778322e-05\n",
      "   4.40738946e-03 -9.99177791e-01  2.27332087e-05  3.82650081e-07\n",
      "  -1.81833548e-05 -8.26336384e-06]\n",
      " [-8.75473606e-02  9.93719099e-01  1.99582921e-04  4.26724008e-05\n",
      "   3.48124989e-07  8.67784810e-05 -1.36484340e-02  8.98604862e-05\n",
      "  -5.63972097e-02  3.86105378e-02  2.99460875e-05  7.41475536e-06\n",
      "   1.04232222e-04  2.10366689e-04]]\n",
      "[0.96851554 0.01881614]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pcaKnownDataset = pca.fit_transform(knownDataset)\n",
    "print(pca.components_)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db38bf36-babe-46e5-a0da-b6dc0927e562",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66757077fdb8400b831c77b90dd4251f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x200324d1fa0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pcaKnownDataset[knownTarget == 0][:,0], pcaKnownDataset[knownTarget == 0][:,1], label=\"0\")\n",
    "ax.scatter(pcaKnownDataset[knownTarget == 1][:,0], pcaKnownDataset[knownTarget == 1][:,1], label=\"1\")\n",
    "ax.legend(bbox_to_anchor=(0, 1, 1, 0), loc=\"lower left\", mode=\"expand\", ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db02eee8-2338-4648-9dde-cdc499bef33e",
   "metadata": {},
   "source": [
    "In PCA we can see that most of the variance is in the altgq feature, which is out of scale. While the graph looks nicely split, zooming in on certain parts shows that the values are in fact intermixed. We also can one hot encode the categorical pass and precise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5da8c0a5-8133-4ab1-b571-77eebd7086a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "ct = ColumnTransformer([\n",
    "        (\"standardScale\", StandardScaler(), ['size', 'vac', 'ci', 'ce', 'refgq', 'altgq']),\n",
    "        (\"oneHot\", OneHotEncoder(handle_unknown='ignore'), ['pass', 'precise'])\n",
    "    ], remainder='passthrough')\n",
    "scaledKnownDataset = ct.fit_transform(knownDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b511e957-f5ae-4c65-8092-ade306e1abcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.23599301e-01  2.56070375e-02  5.52876951e-01 -5.78214513e-01\n",
      "   1.44494435e-02 -3.12647426e-01  5.07089688e-02 -5.07089688e-02\n",
      "   1.88653629e-01 -1.88653629e-01  3.03395369e-03  3.44958955e-04\n",
      "   3.33649445e-02  1.43285808e-04 -5.56863030e-02 -3.74039560e-02]\n",
      " [-3.31583142e-01  7.51404979e-01 -3.13276370e-02  3.34552141e-02\n",
      "  -4.07456457e-02 -5.50091496e-01  8.86284452e-03 -8.86284452e-03\n",
      "  -3.70056010e-02  3.70056010e-02  8.76262874e-02  3.31654785e-03\n",
      "   6.48034783e-02  3.49420262e-03  8.09255590e-03  6.49550569e-02]]\n",
      "[0.40065605 0.19902903]\n"
     ]
    }
   ],
   "source": [
    "pcaScaled = PCA(n_components=2)\n",
    "pcaScaledKnownDataset = pcaScaled.fit_transform(scaledKnownDataset)\n",
    "print(pcaScaled.components_)\n",
    "print(pcaScaled.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3680b398-39fe-4c41-9a1f-8c8fec3295aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8de42686e1247019cf60509af6f0c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x200372d2880>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(pcaScaledKnownDataset[knownTarget == 0][:,0], pcaScaledKnownDataset[knownTarget == 0][:,1], label=\"0\")\n",
    "ax.scatter(pcaScaledKnownDataset[knownTarget == 1][:,0], pcaScaledKnownDataset[knownTarget == 1][:,1], label=\"1\")\n",
    "ax.legend(bbox_to_anchor=(0, 1, 1, 0), loc=\"lower left\", mode=\"expand\", ncol=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b820bae0-70f1-4be4-80a4-5fad195833b5",
   "metadata": {},
   "source": [
    "We see that less variance is explained by a single big value and that the graph seems much less intermixed, which is a good indication that the feature enginnering done above helps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e00fa3-1100-49f7-962d-5d3ad79ce7e4",
   "metadata": {},
   "source": [
    "## Step 3 - constructing a scikit-learn pipeline\n",
    "In this step we will use a scikit-learn pipeline to do our feature engineering, training and model selection for us. Here I will also split out a training portion of the dataset, which will be used for the pipeline and a test portion to measure the final results.\n",
    "\n",
    "A random_state seed of 42 will be used to provide deterministic results in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6282d020-0e63-4c6f-acef-8b69e18312ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "\n",
    "trainData, testData, trainTarget, testTarget = train_test_split(knownDataset, knownTarget, stratify = knownTarget, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3cdb42b2-d321-4242-a701-12c876c7f1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from pipelinehelper import PipelineHelper\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "            ('featureEngineering', ct),\n",
    "            ('classifier', PipelineHelper([\n",
    "                ('tree', DecisionTreeClassifier(random_state=42)),\n",
    "                ('randomForest', RandomForestClassifier(random_state=42)),\n",
    "                ('gradientBoosting', GradientBoostingClassifier(random_state=42)),\n",
    "                ('svm', SVC(random_state=42)),\n",
    "                ('mlp', MLPClassifier(random_state=42, max_iter = 500)),\n",
    "                ('knn', KNeighborsClassifier()),\n",
    "                ('nb', GaussianNB()),\n",
    "                ('gp', GaussianProcessClassifier()),\n",
    "            ]))\n",
    "        ])\n",
    "params = {\n",
    "    'classifier__selected_model': pipeline.named_steps['classifier'].generate({\n",
    "        'tree__criterion': ['gini', 'entropy'],\n",
    "        'tree__splitter': ['best', 'random'],\n",
    "        'tree__max_depth': np.linspace(5, 15, 11),\n",
    "        \n",
    "        'randomForest__n_estimators': [75, 100, 125],\n",
    "        'randomForest__criterion': ['gini', 'entropy'],\n",
    "        'randomForest__max_depth': [3, 5, 8, 10],\n",
    "        'randomForest__class_weight': ['balanced', 'balanced_subsample'],\n",
    "        \n",
    "        'gradientBoosting__loss': ['deviance', 'exponential'],\n",
    "        'gradientBoosting__learning_rate': [0.1, 0.05, 0.01],\n",
    "        'gradientBoosting__n_estimators': [100, 125, 150],\n",
    "        'gradientBoosting__max_depth': [2, 3, 5],\n",
    "        'gradientBoosting__subsample': [0.5 , 0.75, 1],\n",
    "        'gradientBoosting__max_features': [None, 'auto'],\n",
    "        \n",
    "        'svm__C': [0.5, 1, 2],\n",
    "        'svm__kernel': ['linear', 'rbf', 'sigmoid'],\n",
    "        'svm__gamma': ['scale', 'auto'],\n",
    "        'svm__decision_function_shape': ['ovo', 'ovr'],\n",
    "        \n",
    "        'mlp__hidden_layer_sizes': [(20), (50), (10, 5), (20, 10)],\n",
    "        'mlp__activation': ['relu', 'logistic'],\n",
    "        'mlp__learning_rate': ['constant', 'adaptive', 'invscaling'],\n",
    "        'mlp__alpha': [0.001, 0.0001, 0.00001],\n",
    "        \n",
    "        'knn__n_neighbors': [3, 5, 10],\n",
    "        'knn__weights': ['uniform', 'distance'],\n",
    "    }),\n",
    "}\n",
    "crossValidation = StratifiedKFold(n_splits = 5)\n",
    "grid = GridSearchCV(pipeline, params, scoring='f1', n_jobs = 5, cv = crossValidation, verbose = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba22d596-0464-45ef-aeff-a48266f5f14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 532 candidates, totalling 2660 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('featureEngineering',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('standardScale',\n",
       "                                                                         StandardScaler(),\n",
       "                                                                         ['size',\n",
       "                                                                          'vac',\n",
       "                                                                          'ci',\n",
       "                                                                          'ce',\n",
       "                                                                          'refgq',\n",
       "                                                                          'altgq']),\n",
       "                                                                        ('oneHot',\n",
       "                                                                         OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                                         ['pass',\n",
       "                                                                          'precise'])])),\n",
       "                                       ('classifier',\n",
       "                                        Pipeline...\n",
       "                                                         {'criterion': 'entropy',\n",
       "                                                          'max_depth': 6.0,\n",
       "                                                          'splitter': 'random'}),\n",
       "                                                        ('tree',\n",
       "                                                         {'criterion': 'entropy',\n",
       "                                                          'max_depth': 7.0,\n",
       "                                                          'splitter': 'best'}),\n",
       "                                                        ('tree',\n",
       "                                                         {'criterion': 'entropy',\n",
       "                                                          'max_depth': 7.0,\n",
       "                                                          'splitter': 'random'}),\n",
       "                                                        ('tree',\n",
       "                                                         {'criterion': 'entropy',\n",
       "                                                          'max_depth': 8.0,\n",
       "                                                          'splitter': 'best'}),\n",
       "                                                        ('tree',\n",
       "                                                         {'criterion': 'entropy',\n",
       "                                                          'max_depth': 8.0,\n",
       "                                                          'splitter': 'random'}), ...]},\n",
       "             scoring='f1', verbose=4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(trainData, trainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5bef30f8-a443-4802-b6c0-89ca1d632ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classifier__selected_model': ('gradientBoosting',\n",
       "  {'learning_rate': 0.1,\n",
       "   'loss': 'deviance',\n",
       "   'max_depth': 5,\n",
       "   'max_features': None,\n",
       "   'n_estimators': 125,\n",
       "   'subsample': 0.5})}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "afb8fc80-c943-48cc-b7f5-a233c841fa5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__selected_model</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.330136</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.001492</td>\n",
       "      <td>(gradientBoosting, {'learning_rate': 0.1, 'los...</td>\n",
       "      <td>{'classifier__selected_model': ('gradientBoost...</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>0.988827</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>0.980282</td>\n",
       "      <td>0.986539</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.325928</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>(gradientBoosting, {'learning_rate': 0.1, 'los...</td>\n",
       "      <td>{'classifier__selected_model': ('gradientBoost...</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>0.988827</td>\n",
       "      <td>0.985994</td>\n",
       "      <td>0.980282</td>\n",
       "      <td>0.986539</td>\n",
       "      <td>0.003757</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.145708</td>\n",
       "      <td>0.008526</td>\n",
       "      <td>0.016163</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>(randomForest, {'class_weight': 'balanced', 'c...</td>\n",
       "      <td>{'classifier__selected_model': ('randomForest'...</td>\n",
       "      <td>0.988827</td>\n",
       "      <td>0.988764</td>\n",
       "      <td>0.980609</td>\n",
       "      <td>0.988827</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.986072</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.250324</td>\n",
       "      <td>0.010273</td>\n",
       "      <td>0.018551</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>(randomForest, {'class_weight': 'balanced', 'c...</td>\n",
       "      <td>{'classifier__selected_model': ('randomForest'...</td>\n",
       "      <td>0.988827</td>\n",
       "      <td>0.988827</td>\n",
       "      <td>0.980609</td>\n",
       "      <td>0.991597</td>\n",
       "      <td>0.980392</td>\n",
       "      <td>0.986050</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.198672</td>\n",
       "      <td>0.007811</td>\n",
       "      <td>0.017358</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>(randomForest, {'class_weight': 'balanced', 'c...</td>\n",
       "      <td>{'classifier__selected_model': ('randomForest'...</td>\n",
       "      <td>0.988827</td>\n",
       "      <td>0.994382</td>\n",
       "      <td>0.980609</td>\n",
       "      <td>0.988827</td>\n",
       "      <td>0.977528</td>\n",
       "      <td>0.986035</td>\n",
       "      <td>0.006117</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.025468</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.010395</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>(svm, {'C': 0.5, 'decision_function_shape': 'o...</td>\n",
       "      <td>{'classifier__selected_model': ('svm', {'C': 0...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.939828</td>\n",
       "      <td>0.946779</td>\n",
       "      <td>0.912281</td>\n",
       "      <td>0.934873</td>\n",
       "      <td>0.012514</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>0.021742</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.009175</td>\n",
       "      <td>0.001597</td>\n",
       "      <td>(svm, {'C': 0.5, 'decision_function_shape': 'o...</td>\n",
       "      <td>{'classifier__selected_model': ('svm', {'C': 0...</td>\n",
       "      <td>0.969014</td>\n",
       "      <td>0.893983</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.946479</td>\n",
       "      <td>0.905028</td>\n",
       "      <td>0.933159</td>\n",
       "      <td>0.028698</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>0.020478</td>\n",
       "      <td>0.002538</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>(svm, {'C': 0.5, 'decision_function_shape': 'o...</td>\n",
       "      <td>{'classifier__selected_model': ('svm', {'C': 0...</td>\n",
       "      <td>0.969014</td>\n",
       "      <td>0.893983</td>\n",
       "      <td>0.951289</td>\n",
       "      <td>0.946479</td>\n",
       "      <td>0.905028</td>\n",
       "      <td>0.933159</td>\n",
       "      <td>0.028698</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.018940</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.009375</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>(svm, {'C': 2, 'decision_function_shape': 'ovr...</td>\n",
       "      <td>{'classifier__selected_model': ('svm', {'C': 2...</td>\n",
       "      <td>0.944751</td>\n",
       "      <td>0.903409</td>\n",
       "      <td>0.948864</td>\n",
       "      <td>0.949438</td>\n",
       "      <td>0.916427</td>\n",
       "      <td>0.932578</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>0.017744</td>\n",
       "      <td>0.002697</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>(svm, {'C': 2, 'decision_function_shape': 'ovo...</td>\n",
       "      <td>{'classifier__selected_model': ('svm', {'C': 2...</td>\n",
       "      <td>0.944751</td>\n",
       "      <td>0.903409</td>\n",
       "      <td>0.948864</td>\n",
       "      <td>0.949438</td>\n",
       "      <td>0.916427</td>\n",
       "      <td>0.932578</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "131       0.330136      0.006551         0.009375        0.001492   \n",
       "140       0.325928      0.004566         0.009375        0.000798   \n",
       "50        0.145708      0.008526         0.016163        0.002309   \n",
       "67        0.250324      0.010273         0.018551        0.002581   \n",
       "66        0.198672      0.007811         0.017358        0.002057   \n",
       "..             ...           ...              ...             ...   \n",
       "427       0.025468      0.003972         0.010395        0.003112   \n",
       "418       0.021742      0.000978         0.009175        0.001597   \n",
       "424       0.020478      0.002538         0.009676        0.000901   \n",
       "448       0.018940      0.002367         0.009375        0.001016   \n",
       "442       0.017744      0.002697         0.008183        0.000756   \n",
       "\n",
       "                      param_classifier__selected_model  \\\n",
       "131  (gradientBoosting, {'learning_rate': 0.1, 'los...   \n",
       "140  (gradientBoosting, {'learning_rate': 0.1, 'los...   \n",
       "50   (randomForest, {'class_weight': 'balanced', 'c...   \n",
       "67   (randomForest, {'class_weight': 'balanced', 'c...   \n",
       "66   (randomForest, {'class_weight': 'balanced', 'c...   \n",
       "..                                                 ...   \n",
       "427  (svm, {'C': 0.5, 'decision_function_shape': 'o...   \n",
       "418  (svm, {'C': 0.5, 'decision_function_shape': 'o...   \n",
       "424  (svm, {'C': 0.5, 'decision_function_shape': 'o...   \n",
       "448  (svm, {'C': 2, 'decision_function_shape': 'ovr...   \n",
       "442  (svm, {'C': 2, 'decision_function_shape': 'ovo...   \n",
       "\n",
       "                                                params  split0_test_score  \\\n",
       "131  {'classifier__selected_model': ('gradientBoost...           0.991597   \n",
       "140  {'classifier__selected_model': ('gradientBoost...           0.991597   \n",
       "50   {'classifier__selected_model': ('randomForest'...           0.988827   \n",
       "67   {'classifier__selected_model': ('randomForest'...           0.988827   \n",
       "66   {'classifier__selected_model': ('randomForest'...           0.988827   \n",
       "..                                                 ...                ...   \n",
       "427  {'classifier__selected_model': ('svm', {'C': 0...           0.944444   \n",
       "418  {'classifier__selected_model': ('svm', {'C': 0...           0.969014   \n",
       "424  {'classifier__selected_model': ('svm', {'C': 0...           0.969014   \n",
       "448  {'classifier__selected_model': ('svm', {'C': 2...           0.944751   \n",
       "442  {'classifier__selected_model': ('svm', {'C': 2...           0.944751   \n",
       "\n",
       "     split1_test_score  split2_test_score  split3_test_score  \\\n",
       "131           0.985994           0.988827           0.985994   \n",
       "140           0.985994           0.988827           0.985994   \n",
       "50            0.988764           0.980609           0.988827   \n",
       "67            0.988827           0.980609           0.991597   \n",
       "66            0.994382           0.980609           0.988827   \n",
       "..                 ...                ...                ...   \n",
       "427           0.931034           0.939828           0.946779   \n",
       "418           0.893983           0.951289           0.946479   \n",
       "424           0.893983           0.951289           0.946479   \n",
       "448           0.903409           0.948864           0.949438   \n",
       "442           0.903409           0.948864           0.949438   \n",
       "\n",
       "     split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "131           0.980282         0.986539        0.003757                1  \n",
       "140           0.980282         0.986539        0.003757                1  \n",
       "50            0.983333         0.986072        0.003457                3  \n",
       "67            0.980392         0.986050        0.004643                4  \n",
       "66            0.977528         0.986035        0.006117                5  \n",
       "..                 ...              ...             ...              ...  \n",
       "427           0.912281         0.934873        0.012514              527  \n",
       "418           0.905028         0.933159        0.028698              529  \n",
       "424           0.905028         0.933159        0.028698              529  \n",
       "448           0.916427         0.932578        0.019023              531  \n",
       "442           0.916427         0.932578        0.019023              531  \n",
       "\n",
       "[532 rows x 14 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_).sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53b88991-e84d-4774-aff8-cc9f1cda78e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPredictions = grid.predict(trainData)\n",
    "np.average(trainPredictions == trainTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35754aea-d28b-4a92-a420-89f05078c18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9694444444444444"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPredictions = grid.predict(testData)\n",
    "np.average(testPredictions == testTarget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d7f9a27f-f9d5-4273-95b8-e07ee67a20a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10fe35e2804d44c99be4e4f5b64df4aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusionMatrixTest = confusion_matrix(testTarget, testPredictions)\n",
    "fig, ax = plt.subplots()\n",
    "sn.heatmap(confusionMatrixTest, annot=True, cmap = \"RdYlGn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335dfb76-34a7-4c81-b33c-470a985b5f9a",
   "metadata": {},
   "source": [
    "While the accuracy of 100% in the train class indicates overfitting (which is rare for decision trees and forests), the accuracy of 96.9% in test cases is satisfactory for me. We can also see that our model favors false negatives a bit more than false positives. Seeing that the features are not very numerous, it makes sense to me that decision trees, or more precisely gradient boosting forests, led to the best seen results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb519fc-a602-4b96-a424-14f3c2208aba",
   "metadata": {},
   "source": [
    "### Saving the model for later\n",
    "In case we do not want to retrain the model later, the following cell saves it to disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1834db3-1910-4e53-a664-49c2ed70598c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import pickle\n",
    "\n",
    "model = grid.best_estimator_\n",
    "with lzma.open(\"./model.pickle\", \"wb\") as model_file:\n",
    "    pickle.dump(model, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ac3ab6-afd2-4123-83ac-ae2f457297af",
   "metadata": {},
   "source": [
    "To load the model, we can use the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "277ca1c9-d089-46ba-bf8a-f0b1e8ac7d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lzma\n",
    "import pickle\n",
    "with lzma.open(\"./model.pickle\", \"rb\") as model_file:\n",
    "    model = pickle.load(model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aca588-da9b-4ea4-8936-e302a57cd05f",
   "metadata": {},
   "source": [
    "## Step 4 - executing the pipeline on the unknown dataset\n",
    "Finally we have our trained pipeline, which can be used to classify the unknown dataset. In this step we will do just that and save the results into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc7ac3b5-00ef-4287-ae0b-ee07194d6759",
   "metadata": {},
   "outputs": [],
   "source": [
    "unknownPredictions = model.predict(unknownDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eed9977e-b1c9-415e-aa15-2ce13b1380df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEL00000012</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEL00000018</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEL00000020</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEL00000080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEL00000114</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27100</th>\n",
       "      <td>DEL00202501</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27101</th>\n",
       "      <td>DEL00202508</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27102</th>\n",
       "      <td>DEL00202560</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27103</th>\n",
       "      <td>DEL00202579</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27104</th>\n",
       "      <td>DEL00202582</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25666 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id  prediction\n",
       "0      DEL00000012         0.0\n",
       "1      DEL00000018         0.0\n",
       "2      DEL00000020         1.0\n",
       "3      DEL00000080         1.0\n",
       "4      DEL00000114         1.0\n",
       "...            ...         ...\n",
       "27100  DEL00202501         0.0\n",
       "27101  DEL00202508         1.0\n",
       "27102  DEL00202560         1.0\n",
       "27103  DEL00202579         1.0\n",
       "27104  DEL00202582         1.0\n",
       "\n",
       "[25666 rows x 2 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namedPredictions = pd.DataFrame({\n",
    "    \"id\": unknownIds,\n",
    "    \"prediction\": unknownPredictions\n",
    "})\n",
    "namedPredictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0ffba41b-0d70-46b2-b09a-71ba0df634b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "namedPredictions.to_csv('./results.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21770615-0f5a-4abb-ad6f-575aa6ee734f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
